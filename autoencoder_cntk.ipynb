{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "autoencoder_cntk.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s24966904/note/blob/main/autoencoder_cntk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53z66GpfFctT"
      },
      "source": [
        "# 自編碼器Auto-Encoder  (cntk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is_DMTRYFctX"
      },
      "source": [
        "###測試於cntk 2.6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "G0Ga_0MNFctY"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SrNQ5wjFctY"
      },
      "source": [
        "首先引用所有需要的包，其中pickle是用來讀取或是儲存二進位檔(我已經事先將Minist數據處理成二進位檔)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI0zh4iiF1Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa29ca2-0f75-4344-cdc0-8194d8b43831"
      },
      "source": [
        "!apt-get install --no-install-recommends openmpi-bin libopenmpi-dev libopencv-dev python3-opencv python-opencv && ln -sf /usr/lib/x86_64-linux-gnu/libmpi_cxx.so /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.1 && ln -sf /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so.12 && ln -sf /usr/lib/x86_64-linux-gnu/libmpi.so /usr/lib/x86_64-linux-gnu/libmpi.so.12 && pip install cntk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "openmpi-bin is already the newest version (2.1.1-8).\n",
            "openmpi-bin set to manually installed.\n",
            "libopencv-dev is already the newest version (3.2.0+dfsg-4ubuntu0.1).\n",
            "The following NEW packages will be installed:\n",
            "  python-opencv python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 13 not upgraded.\n",
            "Need to get 1,069 kB of archives.\n",
            "After this operation, 5,885 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [535 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [534 kB]\n",
            "Fetched 1,069 kB in 2s (478 kB/s)\n",
            "Selecting previously unselected package python-opencv.\n",
            "(Reading database ... 146374 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-opencv.\n",
            "Preparing to unpack .../python3-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Collecting cntk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/ce/1bbbfcb9767fe1ccaecf68f623da0b98c407345ec74e950d20535ce9c845/cntk-2.7.post2-cp36-cp36m-manylinux1_x86_64.whl (75.1MB)\n",
            "\u001b[K     |████████████████████████████████| 75.1MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from cntk) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from cntk) (1.4.1)\n",
            "Installing collected packages: cntk\n",
            "Successfully installed cntk-2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYUDQvR-FctY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94de1266-75cb-402d-eaa4-6e9f12cb6a9b"
      },
      "source": [
        "from __future__ import print_function \n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import codecs\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "from PIL import Image\n",
        "\n",
        "import cntk as C\n",
        "from cntk.ops import *\n",
        "from cntk.layers import *\n",
        "from cntk.losses import *\n",
        "from cntk.metrics import *\n",
        "from cntk.debugging import *\n",
        "from cntk.logging import *\n",
        "from cntk.learners import *\n",
        "from cntk.train import *\n",
        "from cntk.device import *\n",
        "\n",
        "# 是否使用GPU\n",
        "is_gpu = True\n",
        "if is_gpu:\n",
        "    try_set_default_device(gpu(0))\n",
        "else:\n",
        "    try_set_default_device(cpu())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cntk/cntk_py_init.py:56: UserWarning: Unsupported Linux distribution (ubuntu-18.04). CNTK supports Ubuntu 16.04 and above, only.\n",
            "  warnings.warn('Unsupported Linux distribution (%s-%s). CNTK supports Ubuntu 16.04 and above, only.' % (__my_distro__, __my_distro_ver__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-473ef4060cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mis_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtry_set_default_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtry_set_default_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cntk/internal/swig_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mmap_if_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cntk/device.py\u001b[0m in \u001b[0;36mgpu\u001b[0;34m(device_id)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mcntk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeviceDescriptor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     '''\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcntk_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeviceDescriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Specified GPU device id (0) is invalid.\n\n[CALL STACK]\n[0x7f88bad038a9]                                                       + 0x7b78a9\n[0x7f88bacff154]    CNTK::DeviceDescriptor::  GPUDevice  (unsigned int) + 0xd4\n[0x7f88bbad755d]                                                       + 0xc255d\n[0x50a12f]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x588d41]                                                            \n[0x59fd0e]          PyObject_Call                                      + 0x3e\n[0x50d256]          _PyEval_EvalFrameDefault                           + 0x17e6\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x5161c5]                                                            \n[0x50a12f]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50cc96]          _PyEval_EvalFrameDefault                           + 0x1226\n[0x507be4]                                                            \n[0x508ec2]          _PyFunction_FastCallDict                           + 0x2e2\n[0x594a01]                                                            \n[0x59fd0e]          PyObject_Call                                      + 0x3e\n[0x50d256]          _PyEval_EvalFrameDefault                           + 0x17e6\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50cc96]          _PyEval_EvalFrameDefault                           + 0x1226\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x588d41]                                                            \n[0x59fd0e]          PyObject_Call                                      + 0x3e\n[0x50d256]          _PyEval_EvalFrameDefault                           + 0x17e6\n[0x507be4]                                                            \n[0x588d41]                                                            \n[0x59fd0e]          PyObject_Call                                      + 0x3e\n[0x50d256]          _PyEval_EvalFrameDefault                           + 0x17e6\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x508cd5]          _PyFunction_FastCallDict                           + 0xf5\n[0x594a01]                                                            \n[0x59fd0e]          PyObject_Call                                      + 0x3e\n[0x50d256]          _PyEval_EvalFrameDefault                           + 0x17e6\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x508cd5]          _PyFunction_FastCallDict                           + 0xf5\n[0x594a01]                                                            \n[0x59fd0e]          PyObject_Call                                      + 0x3e\n[0x50d256]          _PyEval_EvalFrameDefault                           + 0x17e6\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x5095c8]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x5161c5]                                                            \n[0x50a12f]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x509900]                                                            \n[0x50a2fd]                                                            \n[0x50beb4]          _PyEval_EvalFrameDefault                           + 0x444\n[0x507be4]                                                            \n[0x588dcd]                                                            \n[0x59fd0e]          PyObject_Call                                      + 0x3e\n[0x63847b]                                                            \n[0x63914f]          Py_Main                                            + 0x45f\n[0x4b0dc0]          main                                               + 0xe0\n[0x7f88ded7cbf7]    __libc_start_main                                  + 0xe7\n[0x5b259a]          _start                                             + 0x2a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ46VfZcFctY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b6c05a0-2223-413e-a409-01210df445ef"
      },
      "source": [
        "C.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TyOsd-dFctZ"
      },
      "source": [
        "將mnist數據進行轉換，請注意，在cntk需要將output轉為onehot(利用np.eye函數)。對於feature除以255，是為了將像素值控制在0~1之間，這樣收斂比較快"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ox1eFi-FctZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "aee478d3-ff23-4a28-811e-bb5d25b212ac"
      },
      "source": [
        "train_data=None\n",
        "test_data=None\n",
        "\n",
        "with open('../Data/mnist_train.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "with open('../Data/mnist_test.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "    \n",
        "def parse_mnist(data):\n",
        "    features=[]\n",
        "    labels=[]\n",
        "    for row in data:\n",
        "        labels.append(np.eye(10)[row[-1]].astype(np.float32))\n",
        "        features.append(row[:-1].astype(np.float32)/255.0)#正規化\n",
        "    return np.asarray(features),np.asarray(labels)\n",
        "\n",
        "\n",
        "\n",
        "features,labels=parse_mnist(train_data)\n",
        "print(features[:3])\n",
        "print(features.shape)\n",
        "print(labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9c0ebe6742a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/mnist_train.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/mnist_test.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/mnist_train.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_xHDNMtFctZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-pPzH1AFcta"
      },
      "source": [
        "idxs=np.arange(0,train_data.shape[0])\n",
        "random.shuffle(idxs)\n",
        "idx=0\n",
        "print(idxs.shape)\n",
        "print(idxs)\n",
        "def get_next_minibatch(minibatch_size):\n",
        "    global idxs,idx\n",
        "    features,labels=parse_mnist(train_data)\n",
        "    x_features=[]\n",
        "    y_labels=[]\n",
        "    while len(x_features)<minibatch_size:\n",
        "        x_features.append(features[idxs[idx]])\n",
        "        y_labels.append(labels[idxs[idx]])\n",
        "        idx+=1\n",
        "        if idx>=len(idxs)-1:\n",
        "            idx=0\n",
        "            random.shuffle(idxs)\n",
        "    return np.asarray(x_features).astype(np.float32),np.asarray(y_labels).astype(np.float32)\n",
        "\n",
        "features_x,labels_y=get_next_minibatch(3)\n",
        "print(features_x.shape)\n",
        "print(labels_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiIy1LabFcta"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5V1tCB7Fcta"
      },
      "source": [
        "features_x,labels_y=get_next_minibatch(32)\n",
        "img=Image.fromarray(np.reshape(features_x[0,:]*255,(28,28)).astype(np.uint8))\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap='gray', interpolation='nearest')\n",
        "\n",
        "print(labels_y[0,:])\n",
        "print(np.argmax(labels[0,:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvgNSX-yFcta"
      },
      "source": [
        "以下我設計了三種autoencoder結構"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PvoQaiBOFcta"
      },
      "source": [
        "def autoencoder(x):#基本型\n",
        "    x=Dense(784,activation=C.relu)(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=Dense(32,activation=None)(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        "    x=Dense(784,activation=C.relu)(x)\n",
        "    x=clip(x,0,1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eU9VoZy-Fcta"
      },
      "source": [
        "def autoencoder1(x):#加入批次正規化\n",
        "    x=Dense(784,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(32,activation=None)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(784,activation=C.relu)(x)\n",
        "    x=clip(x,0,1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "QhQJsMlsFctb"
      },
      "source": [
        "def autoencoder2(x):#加入dropout\n",
        "    x=Dense(784,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dropout(0.2)(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(32,activation=None)(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(784,activation=C.relu)(x)\n",
        "    x=clip(x,0,1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQRf-nBFctb"
      },
      "source": [
        "input_var=C.input_variable(784, dtype=np.float32, name='input_var')\n",
        "\n",
        "z=autoencoder1(input_var)\n",
        "\n",
        "loss=reduce_mean(squared_error(z,input_var))\n",
        "errs=sqrt(reduce_sum(squared_error(z,input_var)/reduce_sum(input_var)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0W5eax0Fctb"
      },
      "source": [
        "progress_printer = ProgressPrinter(freq=200, tag='Training', num_epochs=300)\n",
        "\n",
        "learning_rate=0.001\n",
        "minibatch_size=64\n",
        "num_epochs=3\n",
        "learner = adam(z.parameters, lr=learning_rate_schedule([learning_rate], UnitType.sample, 300),\n",
        "               momentum=momentum_as_time_constant_schedule([minibatch_size / -math.log(0.95)], epoch_size=300),\n",
        "               l1_regularization_weight=0.0001, l2_regularization_weight=5e-3)\n",
        "\n",
        "trainer = Trainer(z, (loss, errs), learner, progress_printer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnkQ8TEjFctb"
      },
      "source": [
        "for epoch_count in range(num_epochs):\n",
        "    mbs = 0\n",
        "    while mbs < len(features)/minibatch_size:\n",
        "        features_x,labels_y=get_next_minibatch(minibatch_size)\n",
        "        trainer.train_minibatch({input_var: features_x})\n",
        "        if mbs%5==0:\n",
        "            z.save('Models/autoencoder_cntk.onnx', format=C.ModelFormat.ONNX)\n",
        "        mbs+=1\n",
        "    trainer.summarize_training_progress()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0HnnZhJFctb"
      },
      "source": [
        "問題\n",
        "(1)為何最中間層的活化函數為None(還有哪些選擇呢?) tanh\n",
        "(2)最後一層的活化函數你覺得relu,sigmoid,leaky relu哪效果比較好呢?\n",
        "(3)三種自編碼器哪一種效果比較好(有沒有和預期不同的地方)\n",
        "(4)如果數值正規化方式改為減127.5除以127.5，請問模型結構該如何調整呢?\n",
        "(5)如果是你 ，還可以如何修改網路結構讓效果更好呢?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRRRr34wFctb"
      },
      "source": [
        "接下來我們比對一下輸入與輸出的差異"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWEGzNWKFctc"
      },
      "source": [
        "features_x,labels_y=get_next_minibatch(minibatch_size)\n",
        "results=z(features_x)#產生預測結果\n",
        "#實際值\n",
        "actual=np.reshape(features_x[0,:]*255,(28,28)).astype(np.uint8)\n",
        "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
        "print(actual.shape)\n",
        "print(pred.shape)\n",
        "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap='gray', interpolation='nearest')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhAmyxjnFctc"
      },
      "source": [
        "# 去噪自編碼器 Denoise AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XMS3kv2Fctc"
      },
      "source": [
        "所謂的去噪自編碼器，輸入值是添加了噪音的數據，但是輸出卻希望他能還原回原來乾淨的數據，這個做法等於是強迫模型自己找出噪音與真實數據間的差異進而分離純化。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZPwCLOrFctc"
      },
      "source": [
        "<img src=\"https://github.com/AllanYiin/DeepBelief_Course4_Examples/blob/master/Images/denoise.jpg?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iO1SDkPFctc"
      },
      "source": [
        "所以唯一需要修正之處在於產生添加噪音的輸入值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpcHq77Fctc"
      },
      "source": [
        "def get_next_noise_minibatch(minibatch_size):\n",
        "    global idxs,idx\n",
        "    features,labels=parse_mnist(train_data)\n",
        "    x_features=[]\n",
        "    x_noise=[]\n",
        "    while len(x_features)<minibatch_size:\n",
        "        x_features.append(features[idxs[idx]])\n",
        "        x_noise.append(features[idxs[idx]]+np.random.standard_normal(784)*0.005)\n",
        "        idx+=1\n",
        "        if idx>=len(idxs):\n",
        "            idx=0\n",
        "            random.shuffle(idxs)\n",
        "    return np.asarray(x_features).astype(np.float32),np.asarray(x_noise).astype(np.float32)\n",
        "\n",
        "features_x,noise_x=get_next_noise_minibatch(3)\n",
        "actual=np.reshape(features_x[0,:]*255,(28,28)).astype(np.uint8)\n",
        "noise=np.reshape(noise_x[0,:]*255,(28,28)).astype(np.uint8)\n",
        "\n",
        "img=Image.fromarray(np.concatenate([actual,noise],axis=-1))\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap='gray', interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqWFZnzhFctc"
      },
      "source": [
        "雖然輸入含噪音數據，但是損失函數則需要比對乾淨的原始值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "oUxs8-cOFctd"
      },
      "source": [
        "input_var=C.input_variable(784, dtype=np.float32, name='input_var')\n",
        "noise_var=C.input_variable(784, dtype=np.float32, name='input_var')\n",
        "\n",
        "z_denoise=autoencoder1(noise_var)\n",
        "\n",
        "loss=reduce_sum(squared_error(z_denoise,input_var))\n",
        "errs=sqrt(reduce_sum(squared_error(z_denoise,input_var)/reduce_sum(input_var)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUyYDfZlFctd"
      },
      "source": [
        "learning_rate=0.001\n",
        "minibatch_size=64\n",
        "num_epochs=3\n",
        "progress_printer1 = ProgressPrinter(freq=200, tag='Training', num_epochs=300)\n",
        "\n",
        "learner1 = adam(z_denoise.parameters, lr=learning_rate_schedule([learning_rate], UnitType.sample, 300),\n",
        "               momentum=momentum_as_time_constant_schedule([minibatch_size / -math.log(0.95)], epoch_size=300),\n",
        "               l1_regularization_weight=0.0001, l2_regularization_weight=5e-3)\n",
        "\n",
        "trainer1 = Trainer(z_denoise, (loss, errs), learner1, progress_printer1)\n",
        "\n",
        "for epoch_count in range(num_epochs):\n",
        "    mbs = 0\n",
        "    while mbs < len(features)/minibatch_size:\n",
        "        raw_features,raw_noise=get_next_noise_minibatch(minibatch_size)\n",
        "        trainer1.train_minibatch({input_var: raw_features,noise_var:raw_noise})\n",
        "        if mbs%5==0:\n",
        "            z_denoise.save('Models/denoise_autoencoder_cntk.onnx', format=C.ModelFormat.ONNX)\n",
        "        mbs+=1\n",
        "    #trainer1.summarize_training_progress()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e46gspf6Fctd"
      },
      "source": [
        "比對原始數據、添加噪音數據以及最後模型生成值，可以看到神經網路學會了如何區分噪音與信息。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_o6L2YMFctd"
      },
      "source": [
        "raw_features,raw_noise=get_next_noise_minibatch(minibatch_size)\n",
        "results=z_denoise(raw_noise)#產生預測結果\n",
        "#實際值\n",
        "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
        "noise=np.reshape(raw_noise[0,:]*255,(28,28)).astype(np.uint8)\n",
        "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
        "\n",
        "img=Image.fromarray(np.concatenate([actual,noise,pred],axis=-1))\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap='gray', interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiANQoejFcte"
      },
      "source": [
        "# 變分自編碼器（VAE）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LLHi5RNFcte"
      },
      "source": [
        "變分自編碼器雖然名字叫做自編碼器，但實際上與自編碼器沒有太多關係，相對的，他反而很常被拿來與GAN相提並論，它的目的都是透過一個隱向量的分布來去生成一群樣本。變分自編碼器不管原始樣本的分布是如何，他都強制轉換為一個常態分配的分布，也就是他的作用是用來進行強制分布變換。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRy4kIH4Fcte"
      },
      "source": [
        "def vae_encoder(x):\n",
        "    x=Dense(784,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def vae_decoder(x):\n",
        "    x=Dense(32,activation=None)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(64,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(128,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(256,activation=C.relu)(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Dense(512,activation=C.relu)(x)\n",
        " \n",
        " \n",
        "    return x\n",
        "\n",
        "latent_dim = 32 # 隱變量維度數\n",
        "\n",
        "h = vae_encoder(input_var)\n",
        "\n",
        "# 算p(Z|X)的均值和方差\n",
        "z_mean = Dense(32)(h)\n",
        "z_log_var = Dense(32)(h)\n",
        "\n",
        "\n",
        "#epsilon表示隨機成分\n",
        "epsilon =C.random.normal(shape=(latent_dim), mean=0.,scale=1)\n",
        "z=z_mean +exp(z_log_var/2)#* epsilon\n",
        "\n",
        "#如果不處理epsilon，則為AUTOENCODER\n",
        "#如果處理epsilon，則為生成模型\n",
        "\n",
        "\n",
        "#解碼層\n",
        "decoder_mean = Dense(784, activation=sigmoid)\n",
        "h_decoded = vae_decoder(z)\n",
        "z_vae= decoder_mean(h_decoded)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEpCvB-nFcte"
      },
      "source": [
        "xent_loss = 784*binary_cross_entropy(z_vae,input_var)#重構損失\n",
        "kl_loss = - 0.5 * reduce_sum(1 + z_log_var - square(z_mean) - exp(z_log_var), axis=-1)#KL散度\n",
        "vae_loss = reduce_mean(xent_loss + kl_loss)\n",
        "\n",
        "loss=vae_loss\n",
        "errs=sqrt(reduce_sum(squared_error(z_vae,input_var)/reduce_sum(input_var)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTEzfwDqFcte"
      },
      "source": [
        "progress_printer2 = ProgressPrinter(freq=200, tag='Training', num_epochs=300)\n",
        "\n",
        "learning_rate=0.0001\n",
        "minibatch_size=64\n",
        "num_epochs=5\n",
        "learner2 = adam(z_vae.parameters, lr=learning_rate_schedule([learning_rate], UnitType.sample, 300),\n",
        "               momentum=momentum_as_time_constant_schedule([minibatch_size / -math.log(0.95)], epoch_size=300),\n",
        "               l1_regularization_weight=0.0001, l2_regularization_weight=5e-3)\n",
        "\n",
        "trainer2 = Trainer(z_vae, (loss, errs), learner2, progress_printer2)\n",
        "for epoch_count in range(num_epochs):\n",
        "    mbs = 0\n",
        "    while mbs < len(features)/minibatch_size:\n",
        "        raw_features,raw_labels=get_next_minibatch(minibatch_size)\n",
        "        trainer2.train_minibatch({input_var: raw_features})\n",
        "        if mbs%5==0:\n",
        "            z_vae.save('Models/vae_cntk.model')\n",
        "        mbs+=1\n",
        "    trainer2.summarize_training_progress()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ETNuZTRFctf"
      },
      "source": [
        "raw_features,raw_labels=get_next_minibatch(minibatch_size)\n",
        "results=z_vae(raw_features)#產生預測結果\n",
        "#實際值\n",
        "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
        "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
        "\n",
        "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap='gray', interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}